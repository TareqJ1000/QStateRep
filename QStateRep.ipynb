{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum State Representation using Artifical Neural Networks\n",
    "\n",
    "Here, we will use a Restricted Boltzmann Machine (or some other appropriate architecture along the way) to represent quantum states. Specifically, we aim to represent the ground state of a quantum many-body system. This obeys the transverse-field Ising model w/ Hamiltonian. \n",
    "\n",
    "$\\hat{H} = -\\sum^{N}_{i=1} \\hat{\\sigma}^{z}_{i} \\hat{\\sigma}^{z}_{i+1} - h \\sum_{i=1}^{N} \\hat{\\sigma}^{x}_{i}$\n",
    "\n",
    "Where $\\hat{\\sigma}_{i}^{z}$ and $\\hat{\\sigma}_{i}^{x}$ are Pauli operators acting on the $i^{th}$ qubit. Here, we can assume that we're normalized wrt the coupling constant $J$, so that the transverse field strength is really in terms of $J$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rbm # This implements the restricted boltzmann machine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pauli operators\n",
    "\n",
    "sigma_x = np.array([[0, 1], [1, 0]])\n",
    "sigma_y = np.array([[0, -1j], [1j, 0]])\n",
    "sigma_z = np.array([[1, 0], [0, -1]])\n",
    "\n",
    "# Initial parameters \n",
    "h=1 # Transverse field stength\n",
    "N=2 # Size of quantum system \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Generation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step is to generate data to train our RBM. We could start by generating the Hamiltonian. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.+0.j  0.+0.j -1.+0.j  0.+0.j]\n",
      " [ 0.+0.j -3.+0.j  0.+0.j -1.+0.j]\n",
      " [-1.+0.j  0.+0.j  1.+0.j  0.+0.j]\n",
      " [ 0.+0.j -1.+0.j  0.+0.j  1.+0.j]]\n"
     ]
    }
   ],
   "source": [
    "def compute_pauli_i(N, i, pauli_type='z'): # Note that i here works in base zero indexing \n",
    "    '''\n",
    "    N - size of many body system\n",
    "    i - which qubit are we acting on? \n",
    "    pauli_type - which pauli operator are we simulating?\n",
    "    '''\n",
    "    pauli_op = np.eye(2) # Or sigma 0\n",
    "    \n",
    "    if (pauli_type=='z'):\n",
    "        pauli_op = sigma_z\n",
    "    elif (pauli_type=='x'):\n",
    "        pauli_op = sigma_x\n",
    "    \n",
    "    # The initialization of the pauli i operator depends on the value of i\n",
    "    \n",
    "    if (i==0):\n",
    "        pauli_i = np.kron(pauli_op, np.eye(2))\n",
    "    else:\n",
    "        pauli_i = np.kron(np.eye(2), np.eye(2))\n",
    "        \n",
    "    #print(pauli_i)\n",
    "    #input()\n",
    "            \n",
    "    for ii in range(N-2): # So we are starting from the ii = 2 position, not ii==0\n",
    "        if (ii+2==i):\n",
    "            pauli_i = np.kron(pauli_i, pauli_op)\n",
    "        else:\n",
    "            pauli_i = np.kron(pauli_i, np.eye(2))\n",
    "        #print(pauli_i)\n",
    "        #input()\n",
    "        \n",
    "    return pauli_i\n",
    "\n",
    "def init_hamil(N): # This instantiates the 2^N by 2^N Hamiltonian we are going to generate\n",
    "    '''\n",
    "    N - number of qubits in the system \n",
    "    '''\n",
    "    # Construct the 2^N by 2^N dimensional Hamiltonian. The initial Hamiltonian is a tensor product of N zero matrices.  \n",
    "\n",
    "    hamil = np.zeros((2,2), dtype=np.complex128)\n",
    "    \n",
    "    for ii in range(N-1): # Since we have already initialized the first element in the tensor product. \n",
    "        temp = np.zeros((2,2), dtype=np.complex128)\n",
    "        hamil = np.kron(hamil, temp)\n",
    "    \n",
    "    return hamil\n",
    "    \n",
    "        \n",
    "def compute_hamiltonian(N, h):\n",
    "    '''\n",
    "    N -- Hamiltonian \n",
    "    h -- transverse field strengh \n",
    "    '''\n",
    "    # Construct the 2^N by 2^N dimensional Hamiltonian. The initial Hamiltonian is a tensor product of N zero matrices.  \n",
    "\n",
    "    hamil = init_hamil(N)\n",
    "    \n",
    "    # Now we compute the sum using the formula \n",
    "    \n",
    "    #print(np.shape(compute_pauli_i(N, 0, pauli_type='z')))\n",
    "    #print(np.shape(compute_pauli_i(N, 1, pauli_type='z')))\n",
    "    #input()\n",
    "    \n",
    "    for ii in range(N):\n",
    "        if (ii+1==N):\n",
    "            hamil += -compute_pauli_i(N, ii, pauli_type='z')@compute_pauli_i(N, 0, pauli_type='z') - h*compute_pauli_i(N, ii, pauli_type='x')\n",
    "        else: \n",
    "            hamil += -compute_pauli_i(N, ii, pauli_type='z')@compute_pauli_i(N, ii+1, pauli_type='z') - h*compute_pauli_i(N, ii, pauli_type='x')\n",
    "        \n",
    "    return hamil\n",
    "\n",
    "#compute_pauli_i(2, 1, pauli_type='z')\n",
    "            \n",
    "hamil = compute_hamiltonian(2,1)\n",
    "\n",
    "#print(hamil)\n",
    "print(hamil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagonalize the Hamiltonian to retrieve the exact ground state. In the diagonalization, this is the eigenvector which has the lowest eigenvalue ... unless h=1, where we actually have degenerate ground states! This seems to be invariant of the size of the quantum system. \n",
    "\n",
    "\n",
    "In this case, a valid ground state could be some probalistic superposition between the two probable ground states. We'll fix $\\alpha = \\beta = \\frac{1}{\\sqrt{2}}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import eigh\n",
    "\n",
    "gnomeState = np.zeros(N, dtype=np.complex128)\n",
    "eigSpectrum, eigSol = eigh(hamil)\n",
    "\n",
    "if (h==1):\n",
    "    groundState1, groundState2 = eigSol[np.argmin(eigSpectrum)], eigSol[np.argmin(eigSpectrum) + 1]\n",
    "    \n",
    "    # Let's create a ground state out of the ground states. Let's fix \\alpha = \\beta = 1/\\sqrt{2}\n",
    "    \n",
    "    gnomeState = (1/np.sqrt(2))*(groundState1 + groundState2)\n",
    "\n",
    "else: \n",
    "    gnomeState = eigSol[np.argmin(eigSpectrum)]\n",
    "    \n",
    "# Check normalization of the ground state\n",
    "\n",
    "print(np.sum(np.abs(gnomeState)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need to compute the basis states in the $\\hat{\\sigma_{z}}$ basis. This will be necessary to compute the NRG Hamiltonian. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from functools import reduce\n",
    "\n",
    "def create_basis_array(N):\n",
    "    '''\n",
    "    The idea is that we create the 2^N combination of possible basis state configurations. A 0 means spin down, 1 means spin up\n",
    "    N - Size of quantum system \n",
    "    '''\n",
    "    \n",
    "    #N = 3  # Change this to whatever length you need\n",
    "    combinations = list(product([0, 1], repeat=N))\n",
    "\n",
    "    for ii in range(len(combinations)):\n",
    "        combinations[ii] = np.array(combinations[ii])\n",
    "    \n",
    "    return combinations\n",
    "\n",
    " \n",
    "def gen_basis_state(N, basis_array): \n",
    "    \n",
    "    '''\n",
    "    N - number of qubits in our system \n",
    "    '''\n",
    "    \n",
    "    #base_ket = np.zeros(2, dtype=np.complex128)\n",
    "    \n",
    "    base_kets = []\n",
    "\n",
    "    # Initialize the complete basis state, which occupies the 2^N dimensional Hilbert space. \n",
    "    \n",
    "    for ii in range(N):\n",
    "        base_kets.append(np.zeros(2, dtype=np.complex128))\n",
    "        \n",
    "    # Now, we modify copies of the base ket by consulting the basis_array \n",
    "    \n",
    "    #print(basis_array)\n",
    "    #print(combo)\n",
    "    #input()\n",
    "    \n",
    "    \n",
    "    full_basis_array = []\n",
    "    \n",
    "    for combo in basis_array: \n",
    "        # Create a new copy of the base_kets \n",
    "        \n",
    "        temp = np.copy(base_kets)\n",
    "        #print(combo)\n",
    "        #input()\n",
    "    \n",
    "        for ii in range(N):\n",
    "            if (combo[ii]==0):\n",
    "                temp[ii] = np.array([1,0], dtype=np.complex128)\n",
    "            elif (combo[ii]==1):\n",
    "                temp[ii] = np.array([0,1], dtype=np.complex128)\n",
    "                \n",
    "        # Finally, compute the kronecker product iteratively across all elements in the array\n",
    "        \n",
    "        kron_result =  reduce(np.kron, temp)\n",
    "        \n",
    "        #print(kron_result)\n",
    "        #input()\n",
    "        full_basis_array.append(kron_result)\n",
    "        \n",
    "    \n",
    "    return full_basis_array\n",
    "     \n",
    "    #for ii in range(N):\n",
    "    \n",
    "your_basis = gen_basis_state(3, create_basis_array(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some functions to compute the NRG expectation value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_hamil(basis_states, m, hamil, psi_basis):\n",
    "    \n",
    "    '''\n",
    "    Computes the local energy as a function on the m^{th} basis state.  \n",
    "    \n",
    "    basis_states -- set of all basis states \n",
    "    m -- Index of m^{th} basis state that is of interest\n",
    "    hamil -- Hamiltonian  \n",
    "    psi_basis --  set of probability amplitudes \n",
    "    '''\n",
    "    \n",
    "    bra_op = lambda ket: np.conjugate(np.transpose(ket))\n",
    "    local_hamil = 0\n",
    "    \n",
    "    for ii in range(len(basis_states)):\n",
    "        local_hamil += bra_op(basis_states[m])@hamil@basis_states[ii]*(psi_basis[ii]/psi_basis[m])\n",
    "    \n",
    "    return local_hamil \n",
    "    \n",
    "    \n",
    "def hamil_expect(basis_states, hamil, psi_basis):\n",
    "    \n",
    "    '''\n",
    "    Computes the Hamiltonian expectatiom value\n",
    "    \n",
    "    basis_states -- set of all basis states \n",
    "    hamil -- Hamiltonian \n",
    "    psi_basis -- set of probability amplitudes \n",
    "    '''\n",
    "    \n",
    "    M = len(basis_states)\n",
    "    hamil_expect = 0\n",
    "    \n",
    "    for m in range(M): \n",
    "        hamil_expect += local_hamil(basis_states, hamil, psi_basis)\n",
    "    return (1/M)*(hamil_expect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBM Architecture\n",
    "\n",
    "We need to compute the gradient update with respect to the Hamiltonian expectation value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1581405990.py, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 24\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def compute_grad(rbm, M):\n",
    "    \n",
    "    '''\n",
    "    Computes (approximately) the gradient of the Hamiltonian expectation value with respect to the trainable parameters of the RBM\n",
    "    rbm -- our RBM to train\n",
    "    M -- number of Gibbs sampling steps \n",
    "    '''\n",
    "    \n",
    "    # Using the RBM, perform Gibbs sampling M times. \n",
    "    \n",
    "    visi_gibbs, hid_gibbs = rbm.gibb_sample(M)\n",
    "    \n",
    "    # Gradient vector. It is of length equal to the set of trainable parameters of the RBM. \n",
    "    \n",
    "    len_bias_visible = len(rbm.bias_visi)\n",
    "    len_bias_hidden = len(rbm.bias_hid)\n",
    "    \n",
    "    len_bias_weight = len_bias_visible*len_bias_hidden\n",
    "    grad_vector = np.zeros(len_bias_visible+len_bias_hidden+len_bias_weight) # Importantly, the first len_bias_visible entries of the vector correspond to the number of bias entries in the visible neurons, \n",
    "    # the next len_bias_hidden entries....\n",
    "    \n",
    "    # Now, using the visible neuron configurations, appoximate the Gibbs sampling. \n",
    "\n",
    "    for mm in range(M):\n",
    "        grad_vector[0:len_bias_visible] += \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This implements the contrastive divergence method for updating the Restricted Boltzmann Machine. Some changes will need to be made in order \n",
    "\n",
    "def contrastive_div(train_dataset, rbm, epochs=10, lr=0.01, batch_size = 5, verbose=0): \n",
    "    num_of_batches = int(len(train_dataset)/batch_size)\n",
    "    start_time = time.time()\n",
    "    # Pick visible configurations from the dataset batchwise\n",
    "    for ii in range(epochs): \n",
    "        print(\"**********\")\n",
    "        print(f\"Epoch {ii}\")\n",
    "        # We need to iterate over the training set. For now, we iterate over datapoints, not batches\n",
    "        for b in range(num_of_batches): \n",
    "            v_batch = train_dataset[batch_size*b:batch_size*(b+1)] # the visible neuron configuration from the dataset\n",
    "            h_stuff_one = [] # the hidden neuron configuration after having done one Gibbs sampling step \n",
    "            h_stuff_two = [] # after two Gibbs sampling step\n",
    "            v_stuff = [] # Sampling the visible neuron config after one Gibbs sampling step. \n",
    "            \n",
    "            for v in v_batch:\n",
    "                # Get h by performing a Gibbs Sampling step \n",
    "                rbm.sample_new_h(v)\n",
    "                # Store the hidden vector for later \n",
    "                h_stuff_one.append(rbm.hid)\n",
    "                # Get v_temp by performing a Gibbs Sampling step \n",
    "                v_temp = rbm.sample_new_v()\n",
    "                v_stuff.append(v_temp)\n",
    "                # Using v_temp, sample a new h vector by performing a Gibbs Sampling step \n",
    "                rbm.sample_new_h(v_temp)\n",
    "                h_stuff_two.append(rbm.hid)\n",
    "            \n",
    "            # The next step is to compute the updates on the weight parameters\n",
    "            # grad_update(self, visi_list_0, hid_list_0, visi_list_1, hid_list_1, i,j, lr, expect='weight')\n",
    "        \n",
    "            rbm.grad_update(v_batch, np.array(h_stuff_one), np.array(v_stuff), np.array(h_stuff_two), lr)\n",
    "            \n",
    "            if(verbose==1):\n",
    "                print(f\"Weights: {rbm.weights} \")\n",
    "                print(f\"Visible Bias: {rbm.bias_visi}\")\n",
    "                print(f\"Hidden Bias: {rbm.bias_hid}\")\n",
    "                \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
