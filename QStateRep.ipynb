{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum State Representation using Artifical Neural Networks\n",
    "\n",
    "Here, we will use a Restricted Boltzmann Machine (or some other appropriate architecture along the way) to represent quantum states. Specifically, we aim to represent the ground state of a quantum many-body system. This obeys the transverse-field Ising model w/ Hamiltonian. \n",
    "\n",
    "$\\hat{H} = -\\sum^{N}_{i=1} \\hat{\\sigma}^{z}_{i} \\hat{\\sigma}^{z}_{i+1} - h \\sum_{i=1}^{N} \\hat{\\sigma}^{x}_{i}$\n",
    "\n",
    "Where $\\hat{\\sigma}_{i}^{z}$ and $\\hat{\\sigma}_{i}^{x}$ are Pauli operators acting on the $i^{th}$ qubit. Here, we can assume that we're normalized wrt the coupling constant $J$, so that the transverse field strength is really in terms of $J$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rbm # This implements the restricted boltzmann machine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pauli operators\n",
    "\n",
    "sigma_x = np.array([[0, 1], [1, 0]])\n",
    "sigma_y = np.array([[0, -1j], [1j, 0]])\n",
    "sigma_z = np.array([[1, 0], [0, -1]])\n",
    "\n",
    "# Initial parameters \n",
    "h=1 # Transverse field stength\n",
    "N=2 # Size of quantum system \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Generation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step is to generate data to train our RBM. We could start by generating the Hamiltonian. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.+0.j  0.+0.j -1.+0.j  0.+0.j]\n",
      " [ 0.+0.j -3.+0.j  0.+0.j -1.+0.j]\n",
      " [-1.+0.j  0.+0.j  1.+0.j  0.+0.j]\n",
      " [ 0.+0.j -1.+0.j  0.+0.j  1.+0.j]]\n"
     ]
    }
   ],
   "source": [
    "def compute_pauli_i(N, i, pauli_type='z'): # Note that i here works in base zero indexing \n",
    "    '''\n",
    "    N - size of many body system\n",
    "    i - which qubit are we acting on? \n",
    "    pauli_type - which pauli operator are we simulating?\n",
    "    '''\n",
    "    pauli_op = np.eye(2) # Or sigma 0\n",
    "    \n",
    "    if (pauli_type=='z'):\n",
    "        pauli_op = sigma_z\n",
    "    elif (pauli_type=='x'):\n",
    "        pauli_op = sigma_x\n",
    "    \n",
    "    # The initialization of the pauli i operator depends on the value of i\n",
    "    \n",
    "    if (i==0):\n",
    "        pauli_i = np.kron(pauli_op, np.eye(2))\n",
    "    else:\n",
    "        pauli_i = np.kron(np.eye(2), np.eye(2))\n",
    "        \n",
    "    #print(pauli_i)\n",
    "    #input()\n",
    "            \n",
    "    for ii in range(N-2): # So we are starting from the ii = 2 position, not ii==0\n",
    "        if (ii+2==i):\n",
    "            pauli_i = np.kron(pauli_i, pauli_op)\n",
    "        else:\n",
    "            pauli_i = np.kron(pauli_i, np.eye(2))\n",
    "        #print(pauli_i)\n",
    "        #input()\n",
    "        \n",
    "    return pauli_i\n",
    "\n",
    "def init_hamil(N): # This instantiates the 2^N by 2^N Hamiltonian we are going to generate\n",
    "    '''\n",
    "    N - number of qubits in the system \n",
    "    '''\n",
    "    # Construct the 2^N by 2^N dimensional Hamiltonian. The initial Hamiltonian is a tensor product of N zero matrices.  \n",
    "\n",
    "    hamil = np.zeros((2,2), dtype=np.complex128)\n",
    "    \n",
    "    for ii in range(N-1): # Since we have already initialized the first element in the tensor product. \n",
    "        temp = np.zeros((2,2), dtype=np.complex128)\n",
    "        hamil = np.kron(hamil, temp)\n",
    "    \n",
    "    return hamil\n",
    "    \n",
    "        \n",
    "def compute_hamiltonian(N, h):\n",
    "    '''\n",
    "    N -- Hamiltonian \n",
    "    h -- transverse field strengh \n",
    "    '''\n",
    "    # Construct the 2^N by 2^N dimensional Hamiltonian. The initial Hamiltonian is a tensor product of N zero matrices.  \n",
    "\n",
    "    hamil = init_hamil(N)\n",
    "    \n",
    "    # Now we compute the sum using the formula \n",
    "    \n",
    "    #print(np.shape(compute_pauli_i(N, 0, pauli_type='z')))\n",
    "    #print(np.shape(compute_pauli_i(N, 1, pauli_type='z')))\n",
    "    #input()\n",
    "    \n",
    "    for ii in range(N):\n",
    "        if (ii+1==N):\n",
    "            hamil += -compute_pauli_i(N, ii, pauli_type='z')@compute_pauli_i(N, 0, pauli_type='z') - h*compute_pauli_i(N, ii, pauli_type='x')\n",
    "        else: \n",
    "            hamil += -compute_pauli_i(N, ii, pauli_type='z')@compute_pauli_i(N, ii+1, pauli_type='z') - h*compute_pauli_i(N, ii, pauli_type='x')\n",
    "        \n",
    "    return hamil\n",
    "\n",
    "#compute_pauli_i(2, 1, pauli_type='z')\n",
    "            \n",
    "hamil = compute_hamiltonian(2,1)\n",
    "\n",
    "#print(hamil)\n",
    "print(hamil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagonalize the Hamiltonian to retrieve the exact ground state. In the diagonalization, this is the eigenvector which has the lowest eigenvalue ... unless h=1, where we actually have degenerate ground states! This seems to be invariant of the size of the quantum system. \n",
    "\n",
    "\n",
    "In this case, a valid ground state could be some probalistic superposition between the two probable ground states. We'll fix $\\alpha = \\beta = \\frac{1}{\\sqrt{2}}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import eigh\n",
    "\n",
    "gnomeState = np.zeros(N, dtype=np.complex128)\n",
    "eigSpectrum, eigSol = eigh(hamil)\n",
    "\n",
    "if (h==1):\n",
    "    groundState1, groundState2 = eigSol[np.argmin(eigSpectrum)], eigSol[np.argmin(eigSpectrum) + 1]\n",
    "    \n",
    "    # Let's create a ground state out of the ground states. Let's fix \\alpha = \\beta = 1/\\sqrt{2}\n",
    "    \n",
    "    gnomeState = (1/np.sqrt(2))*(groundState1 + groundState2)\n",
    "\n",
    "else: \n",
    "    gnomeState = eigSol[np.argmin(eigSpectrum)]\n",
    "    \n",
    "# Check normalization of the ground state\n",
    "\n",
    "print(np.sum(np.abs(gnomeState)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBM Architecture\n",
    "\n",
    "This is mostly stuff we've coded up from assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This implements the contrastive divergence method for updating the Restricted Boltzmann Machine. Some changes will need to be made in order \n",
    "\n",
    "def contrastive_div(train_dataset, rbm, epochs=10, lr=0.01, batch_size = 5, verbose=0): \n",
    "    num_of_batches = int(len(train_dataset)/batch_size)\n",
    "    start_time = time.time()\n",
    "    # Pick visible configurations from the dataset batchwise\n",
    "    for ii in range(epochs): \n",
    "        print(\"**********\")\n",
    "        print(f\"Epoch {ii}\")\n",
    "        # We need to iterate over the training set. For now, we iterate over datapoints, not batches\n",
    "        for b in range(num_of_batches): \n",
    "            v_batch = train_dataset[batch_size*b:batch_size*(b+1)] # the visible neuron configuration from the dataset\n",
    "            h_stuff_one = [] # the hidden neuron configuration after having done one Gibbs sampling step \n",
    "            h_stuff_two = [] # after two Gibbs sampling step\n",
    "            v_stuff = [] # Sampling the visible neuron config after one Gibbs sampling step. \n",
    "            \n",
    "            for v in v_batch:\n",
    "                # Get h by performing a Gibbs Sampling step \n",
    "                rbm.sample_new_h(v)\n",
    "                # Store the hidden vector for later \n",
    "                h_stuff_one.append(rbm.hid)\n",
    "                # Get v_temp by performing a Gibbs Sampling step \n",
    "                v_temp = rbm.sample_new_v()\n",
    "                v_stuff.append(v_temp)\n",
    "                # Using v_temp, sample a new h vector by performing a Gibbs Sampling step \n",
    "                rbm.sample_new_h(v_temp)\n",
    "                h_stuff_two.append(rbm.hid)\n",
    "            \n",
    "            # The next step is to compute the updates on the weight parameters\n",
    "            # grad_update(self, visi_list_0, hid_list_0, visi_list_1, hid_list_1, i,j, lr, expect='weight')\n",
    "        \n",
    "            rbm.grad_update(v_batch, np.array(h_stuff_one), np.array(v_stuff), np.array(h_stuff_two), lr)\n",
    "            \n",
    "            if(verbose==1):\n",
    "                print(f\"Weights: {rbm.weights} \")\n",
    "                print(f\"Visible Bias: {rbm.bias_visi}\")\n",
    "                print(f\"Hidden Bias: {rbm.bias_hid}\")\n",
    "                \n",
    "                \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
